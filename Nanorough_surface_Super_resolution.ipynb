{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nanorough surface Super-resolution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMTNbMVyQYzWhR+DUD3o7D2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/billsioros/thesis/blob/master/Nanorough_surface_Super_resolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XIigYPTAMAH"
      },
      "source": [
        "# Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1mdRrYGM60R"
      },
      "source": [
        "## Pip Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fDiW2N-M60S",
        "outputId": "0eac1516-c4f0-406f-c009-133d309c2dc4"
      },
      "source": [
        "!pip install torch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WktNsUHMAS63"
      },
      "source": [
        "## RNG Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1mLAArpLX7A"
      },
      "source": [
        "We are going to be seed the random number generator engines, so that our results are reproducible accross different set ups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMnousxlAbPV"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "if SEED is not None:\n",
        "  np.random.seed(SEED)\n",
        "  random.seed(SEED)\n",
        "  torch.manual_seed(SEED)\n",
        "  torch.cuda.manual_seed(SEED)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  os.environ['PYTHONHASHSEED'] = str(SEED)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxhexKDEM60T"
      },
      "source": [
        "## Determining the Current Working Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oRdJanBM60T"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "BASE_DIR = Path.cwd()\n",
        "BASE_DIR.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iShoshCpZHI"
      },
      "source": [
        "# Dataset Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXcHJTxNproO"
      },
      "source": [
        "from torch.utils.data.dataset import  Dataset\n",
        "\n",
        "class NanoroughDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def __len__(self):\n",
        "    pass\n",
        "  \n",
        "  def __getitem__(self):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og5CT1AHeZeD"
      },
      "source": [
        "# Training and Testing Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwcDSjQ6eeIV"
      },
      "source": [
        "from time import time\n",
        "from functools import wraps\n",
        "\n",
        "def benchmark(method=None, *, debug=False):\n",
        "  def _(method):\n",
        "    @wraps(method)\n",
        "    def wrapper(*args, **kwargs):\n",
        "      beg = time()\n",
        "      rv = method(*args, **kwargs)\n",
        "      end = time()\n",
        "\n",
        "      if debug is True:\n",
        "        args_str = ', '.join(str(x) for x in args)\n",
        "        kwargs_str = ', '.join(\"{}={}\".format(x, y) for x, y in kwargs.items())\n",
        "\n",
        "        print(\"%s(%s, %s) returned %s after %7.3f seconds\" % (method.__name__, args_str, kwargs_str, str(rv), (end - beg)))\n",
        "      else:\n",
        "        print(\"%s returned after %7.3f seconds\" % (method.__name__, (end - beg)))\n",
        "\n",
        "      return rv\n",
        "\n",
        "    return wrapper\n",
        "  \n",
        "  return _ if method is None else _(method)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKYZzDBfeloB"
      },
      "source": [
        "@benchmark\n",
        "def train_epoch(model, bucket_iterator, optimizer, criterion, log_every_n=None):\n",
        "  model.train()\n",
        "\n",
        "  train_loss = 0\n",
        "  for train_iteration, batch in enumerate(bucket_iterator):\n",
        "    if log_every_n is not None and not train_iteration % log_every_n:\n",
        "      print(f\"Training Iteration #{train_iteration:04d}\")\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y_pred = model(X_batch).squeeze()\n",
        "    \n",
        "    loss = criterion(y_pred, y_batch)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    \n",
        "    train_loss += loss.item() / len(bucket_iterator)\n",
        "\n",
        "  return train_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtByIV7Rem8l"
      },
      "source": [
        "from torch import no_grad\n",
        "\n",
        "@benchmark\n",
        "def test_epoch(model, bucket_iterator, criterion, log_every_n=None):\n",
        "  model.eval()\n",
        "\n",
        "  test_loss =  0\n",
        "  with no_grad():\n",
        "    for test_iteration, batch in enumerate(bucket_iterator):\n",
        "      X_batch, y_batch = batch.tweet, batch.sentiment\n",
        "      if log_every_n is not None and not test_iteration % log_every_n:\n",
        "        print(f\"Testing Iteration #{test_iteration:04d}\")\n",
        "\n",
        "      y_pred = model(X_batch).squeeze()\n",
        "\n",
        "      loss = criterion(y_pred, y_batch)\n",
        "      \n",
        "      test_loss += loss.item() / len(bucket_iterator)\n",
        "    \n",
        "  return test_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ovsp2b7b7ho"
      },
      "source": [
        "# A naive-approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w9JbffHcmtD"
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsKgzXIic12b"
      },
      "source": [
        "class PerceptronNetwork(nn.Module):\n",
        "  def __init__(self, in_features, out_features):\n",
        "    super().__init__()\n",
        "\n",
        "    self.linear = nn.Linear(in_features, out_features)\n",
        "    self.activation = nn.ReLU()\n",
        "  \n",
        "  def forward(self, batch):\n",
        "    return self.activation(self.linear(batch))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7U_XBLyk_MU"
      },
      "source": [
        "CHECKPOINT_DIR, N_EPOCHS, LEARNING_RATE, WEIGHT_DECAY = None, 10, 0.001, 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "LL4rA1I-j_Rq",
        "outputId": "133f999e-e5b7-4911-bd1d-145fca0a5e0b"
      },
      "source": [
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.nn import MSELoss\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda:0\"\n",
        "  if torch.cuda.device_count() > 1:\n",
        "    model = nn.DataParallel(model)\n",
        "\n",
        "device = torch.device(device)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = MSELoss.to(device)\n",
        "\n",
        "optimizer = Adam(filter(lambda x: x.requires_grad, PerceptronNetwork(2, 2).parameters()), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = ReduceLROnPlateau(optimizer=optimizer)\n",
        "\n",
        "# train_iter, test_iter = data.BucketIterator.splits(\n",
        "#   (train_data, test_data),\n",
        "#   sort_key=lambda x: len(x.tweet),\n",
        "#   shuffle=True,\n",
        "#   batch_size=256,\n",
        "#   device=device\n",
        "# )\n",
        "\n",
        "train_losses, test_losses = [], []\n",
        "for epoch in range(n_epochs):\n",
        "  train_loss = train_epoch(model, train_iter, optimizer, criterion, log_every_n)\n",
        "\n",
        "  test_loss = test_epoch(model, test_iter, criterion, log_every_n)\n",
        "  \n",
        "  if CHECKPOINT_DIR is not None and (not test_losses or test_loss < min(test_losses)):\n",
        "    torch.save(model.state_dict(), CHECKPOINT_DIR / f'{epoch:03d}.mt')\n",
        "\n",
        "  print(\"Epoch: %02d, Train Loss: %7.3f, Test Loss: %7.3f\" % (epoch, train_loss, test_loss))\n",
        "\n",
        "  if scheduler is not None:\n",
        "    scheduler.step(test_loss)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f48e130e96f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# criterion = BCEWithLogitsLoss().to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}